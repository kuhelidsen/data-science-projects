{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Titanic Dataset","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"}},{"cell_type":"code","source":"# Import Basic Packages for data exploration and wrangling\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import norm\nfrom scipy import stats\n\n# Import visualization packages\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport datetime       # Added for version 4 (to post output file with date/time)\n\n# sklearn pre-processing\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.impute import KNNImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import SelectKBest,f_regression\nfrom sklearn.metrics import classification_report,confusion_matrix,make_scorer,f1_score\n# sklearn models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import VotingClassifier\n","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Load and Exploration","metadata":{}},{"cell_type":"code","source":"titanic_tr = pd.read_csv('../input/titanic/train.csv')\ntitanic_tst = pd.read_csv('../input/titanic/test.csv')\ntitanic_tst","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_tr.head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Initial Column Types (prior to deep inspection):**\n\nCategorical Variables:\n* Pclass\n* Sex (might be binary)\n* SibSp\n* Parch\n* Embarked\n\nContinuous Variables:\n* Age\n* Fare\n\nNatural Language:\n* Name\n* Cabin","metadata":{}},{"cell_type":"code","source":"# Verify column types\ntitanic_tr.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verified data ranges for age and fare\n# Information shows null values; summarize the number of null values\ntitanic_tr.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SHow the divide between those who survived and those who did not\ntitanic_tr['Survived'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show potential values of all categorical variables\ncat_vars = ['Pclass','Sex','SibSp','Parch','Embarked']\n\nfor var in cat_vars :\n    print(var)\n    print('==============================')\n    print(titanic_tr[var].value_counts())\n    print('')\n    print('')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize numeric ranges\ncont_var = ['Age','Fare']\n\nfig = make_subplots(rows=1, cols=2)\n\nfor idx, var in enumerate(cont_var):\n   fig.add_trace(go.Violin(y=titanic_tr[var], box_visible=True, line_color='white', meanline_visible=True, fillcolor='darkturquoise', opacity=0.5, \n                           points='all', x0=var), 1, idx + 1) \n\nfig.update_layout(height=800, width = 1200, title_text = 'Continuous Variable Distribution', showlegend=False, template='plotly_dark')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There are clear outliers on the Fare variable, though they are likely valid due to the high cost of first class tickets.\n\n# View split violin plots, showing those that survived and those that did not.\nfig = make_subplots(rows = 1, cols = 2)\n\nfor idx, var in enumerate(cont_var):\n    fig.add_trace(go.Violin(y=titanic_tr[var][ titanic_tr['Survived'] == 1 ],\n                            line_color='white', fillcolor='darkturquoise', opacity=0.5, \n                            legendgroup='Yes', name='Yes', side='negative', scalegroup='Yes',\n                       x0=var), 1, idx + 1)\n    fig.add_trace(go.Violin(y=titanic_tr[var][ titanic_tr['Survived'] == 0 ],\n                            line_color='white', fillcolor='darkorange', opacity=0.5, \n                            legendgroup='Yes', name='No', side='positive', scalegroup='No',\n                       x0=var), 1, idx + 1)\n\nfig.update_traces(meanline_visible=True)\nfig.update_layout(height=800, width=1200, violinmode='overlay',\n                  title_text = 'Continuous Variable Distribution - Survived Compared', \n                  template=\"plotly_dark\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graph above helps to determine how to manage outliers.  Generally speaking, those above the age of 70 did not survive.  Also, generally speaking, those who paid a far above $100 survived.  ","metadata":{}},{"cell_type":"code","source":"# Display an sns plot for all numeric data types\ntitanic_num = titanic_tr.select_dtypes('number').drop(columns=['PassengerId'])\nplt.style.use('dark_background')\nsns.pairplot(titanic_num)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View using a heatmap\ncorr = titanic_num.corr()\nfig = px.imshow(corr)\nfig.update_layout(title_text = 'Correlation Heat Map - Numerical Fields', template=\"plotly_dark\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Transformation and Pre-Processing","metadata":{}},{"cell_type":"code","source":"# Combine Train and Test, ensuring that all pre-processing steps are managed simultaneously\ntrain_rows = titanic_tr.shape[0]\ntest_rows = titanic_tst.shape[0]\nprint('Rows in the train dataset: ', train_rows)\nprint('Rows in the test dataset: ', test_rows)\ntitanic_cmb = pd.concat([titanic_tr.iloc[:, 2:], titanic_tst.iloc[:, 1:]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Included new columns \"Cab\", \"Title\", \"FamilySize\", \"Solo\", \"SmFam\", \"LgFam\", \"numeric_ticket\", \"IsMale\" ","metadata":{}},{"cell_type":"code","source":"# Multiple cabins:\ntitanic_cmb['Cabin_multiple'] = titanic_cmb.Cabin.apply(lambda x:0 if pd.isna(x) else len(x.split(' ')))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Manage outliers, using the extremes listed above\ntitanic_cmb.Age[titanic_cmb.Age >= 70] = 70\ntitanic_cmb.Fare[titanic_cmb.Fare >= 100] = 100\n\n# creates catagories based on the cabin letter:\n# in this case we will treat null value like its own catagory:\ntitanic_cmb.Cabin.fillna('U', inplace = True)\ntitanic_cmb['Cab'] = titanic_cmb.Cabin.apply(lambda x: str(x)[0])\n\n# including a new column \"FamiySize\":\ntitanic_cmb['FamilyCt'] = titanic_cmb['Parch'] + titanic_cmb['SibSp'] + 1\ntitanic_cmb['FamilySize'] = np.select([\n    titanic_cmb['FamilyCt'] == 1,\n    titanic_cmb['FamilyCt'].between(2,4, inclusive=True),\n    titanic_cmb['FamilyCt'] >= 5\n],\n[\n    'Solo',\n    'SmFam',\n    'LgFam'\n])\n\n# Replace empty Embarked fields using the most common value (S)\ntitanic_cmb['Embarked'] = titanic_cmb['Embarked'].fillna('S')\n\n# feature engineering on person's title:\ntitanic_cmb['Title'] = titanic_cmb.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\n\n# Organize by sex-based honorifics\n                             \nrep = ['Countess','Lady','Sir','Don','Jonkheer','Dona','Rev','Dr','Col','Major','Capt','Mrs','Ms','Mme','Mr','Miss','Mlle','Master']\nwth = ['Royalty','Royalty','Royalty','Royalty','Royalty','Royalty','Officer','Officer','Officer','Officer','Officer','Mrs','Mrs','Mrs','Mr','Miss','Miss','Master']\n\ntitanic_cmb['Title2'] = titanic_cmb['Title'].replace(rep,wth)\n\n# catagorizing tickets as numeric and non numeric:\ntitanic_cmb['numeric_ticket'] = titanic_cmb.Ticket.apply(lambda x:1 if x.isnumeric() else 0)\n\ntitanic_cmb['ticket_letters'] = titanic_cmb.Ticket.apply(lambda x:''.join(x.split(' ')[:-1]).replace('.','').replace('/','').lower() if len(x.split(' ')[:-1]) > 0 else 0) \n\n# Break the fare into quantiles\ntitanic_cmb['FareCut']= pd.qcut(titanic_tr['Fare'], [0, .3, .6, .8, .9, 1],\n                                labels=[\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\"])\n\n# Convert the Sex column to binary IsMale\ntitanic_cmb['IsMale'] = np.where(titanic_cmb.Sex == 'male', 1, 0)\n\ntitanic_cmb.head(10)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There is a gradual decrease in survival rate going from Cabin A to n (unassigned) Cabin","metadata":{}},{"cell_type":"code","source":"# comparing survival rate by cabin for the training dataset:\ntitanic_train = titanic_cmb.iloc[0:891,0:]\nprint(titanic_train['Cab'].value_counts())\npd.pivot_table(titanic_train, index = titanic_tr['Survived'], columns = titanic_train['Cab'], values = 'Name', aggfunc = 'count')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train.Cabin_multiple.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(titanic_train, index = titanic_tr['Survived'], columns = titanic_train['Cabin_multiple'], values = 'Ticket', aggfunc = 'count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The \"name_title\"  shows that people with tilte Mrs., Miss, Ms, Master ( Female and kids) survived more as compared to Mr. ( Males)","metadata":{}},{"cell_type":"code","source":"# comparing survival rate by name_title for training set:\nprint(titanic_train.Title.value_counts())\n\npd.pivot_table(titanic_train, index = titanic_tr['Survived'], columns = titanic_train['Title'], values = 'Name', aggfunc = 'count')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The new column \"numeric_ticket\" is created with two catagories: numeric ticket (1) ( numbered tickets) and non-numeric ticket (0) ( a mix of letters and numbers) : Survival rate is same for numeric and non-numeric tickets.","metadata":{}},{"cell_type":"code","source":"# comparing survival rate by numeric_ticket of the training dataset:\nprint(titanic_train.numeric_ticket.value_counts())\n\npd.pivot_table(titanic_train, index = titanic_tr['Survived'], columns = titanic_train['numeric_ticket'], values = 'Name', aggfunc = 'count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### New column \"FamilySize\" vs Survival shows that passengers having small family size had  higher survival","metadata":{}},{"cell_type":"code","source":"# comparing survival by FamilySize of the training dataset:\nprint(titanic_train.FamilySize.value_counts())\n\npd.pivot_table(titanic_train, index = titanic_tr['Survived'], columns = titanic_train['FamilySize'], values = 'Name', aggfunc = 'count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"T = pd.concat([titanic_tr.loc[:,'Survived'], titanic_train.iloc[0:,0:]], axis=1)\ncor = T.corr()\nprint(cor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate Column Types\ncont_vars = ['Age']\nbin_vars = ['IsMale']\ncat_vars = ['FareCut','Embarked', 'Pclass', 'Cab', 'Title2', 'FamilySize']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cont_pipeline = Pipeline([\n    ('imputer', KNNImputer(n_neighbors=2)),\n    ('std_scaler', StandardScaler()),\n])\n\ncat_pipeline = Pipeline([\n#    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder()),\n])\n\nfull_pipeline = ColumnTransformer([\n    ('continuous', cont_pipeline, cont_vars),\n    ('binary', 'passthrough', bin_vars),\n    ('category', cat_pipeline, cat_vars)\n], sparse_threshold=0)\n\n# Get a list of column names\ncat_col_names = OneHotEncoder().fit(titanic_cmb[cat_vars]).get_feature_names(cat_vars)\ncol_names = [*cont_vars, *bin_vars, *cat_col_names]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Establish ML datasets\nX = full_pipeline.fit_transform(titanic_cmb)\n\nX_train = X[0:train_rows, 0:]\nX_test = X[train_rows:, 0:]\ny_train = titanic_tr['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Creation and Tracking","metadata":{}},{"cell_type":"code","source":"# Establish variables that will be used for each model\ncross_val = 10\nrnd_st = 2020\n\n# Create a dataframe that will be used for comparison\nresults = pd.DataFrame(columns = ['Model Type','Model Name','Accuracy','Hyperparameters'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"log_grd = LogisticRegression(random_state=rnd_st)\n\nparam_grid_log = [\n    {'penalty' : ['l1','l2'], 'C':[1, 5, 10, 15], 'class_weight': ['balanced', None], \n     'solver' : ['liblinear']},\n    {'penalty' : ['elasticnet'], 'C':[1,5, 10, 15], 'class_weight':['balanced', None],\n    'solver' : ['saga'], 'max_iter':[10000], 'l1_ratio' : [0.25, 0.5, 0.75]}\n]\n\ngrid_search_log = GridSearchCV(log_grd, param_grid_log, cv = cross_val, scoring='accuracy', \n                               return_train_score=True)\n\ngrid_search_log.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search_log.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View the scores of all permutations\ncvres = grid_search_log.cv_results_\nfor mean_score, params in zip(cvres['mean_test_score'], cvres['params']) :\n    print(round(mean_score, 4), params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = results.append({'Model Type' : 'Logistic Regression',\n                          'Model Name' : 'grid_search_log',\n                          'Accuracy' : grid_search_log.best_score_ ,\n                          'Hyperparameters' : grid_search_log.best_params_}, ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree","metadata":{}},{"cell_type":"code","source":"tree_grd = DecisionTreeClassifier(random_state = rnd_st)\n\nparam_grid_tree = [\n    {'splitter' : ['best','random'],\n    'max_depth' : [3,5,7,9],\n    'max_features' : ['auto','sqrt','log2']},\n]\n\ngrid_search_tree = GridSearchCV(tree_grd, param_grid_tree, cv = cross_val, scoring='accuracy',\n                               return_train_score=True)\ngrid_search_tree.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search_tree.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cvres = grid_search_tree.cv_results_\nfor mean_score, params in zip(cvres['mean_test_score'], cvres['params']) :\n    print(round(mean_score, 4), params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = results.append({'Model Type' : 'Decision Tree',\n                          'Model Name' : 'grid_search_tree',\n                          'Accuracy' : grid_search_tree.best_score_ ,\n                          'Hyperparameters' : grid_search_tree.best_params_}, ignore_index=True)\n\n# View results so far\nresults","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Support Vector Machine","metadata":{}},{"cell_type":"code","source":"svm_grd = SVC(random_state = rnd_st)\n\nparam_grid_svm = [\n    {'kernel' : ['linear','poly','rbf','sigmoid'],\n    'coef0' : [0, 1],\n    'decision_function_shape' : ['ovo','ovr']\n    },\n]\n\ngrid_search_svm = GridSearchCV(svm_grd, param_grid_svm, cv = cross_val, scoring='accuracy', \n                               return_train_score=True)\n\ngrid_search_svm.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the best estimator\ngrid_search_svm.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cvres = grid_search_svm.cv_results_\nfor mean_score, params in zip(cvres['mean_test_score'], cvres['params']) :\n    print(round(mean_score, 4), params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = results.append({'Model Type' : 'Support Vector Machine',\n                          'Model Name' : 'grid_search_svm',\n                          'Accuracy' : grid_search_svm.best_score_ ,\n                          'Hyperparameters' : grid_search_svm.best_params_}, ignore_index=True)\n\n# View results so far\nresults","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"code","source":"rf_grd = RandomForestClassifier(random_state = rnd_st, n_estimators=100, criterion='gini')\n\nparam_grid_rf = [\n    {\n        'max_depth' : [3,5,7,9],\n        'class_weight' : ['balanced','balanced_subsample']\n    },\n]\n\ngrid_search_rf = GridSearchCV(rf_grd, param_grid_rf, cv = cross_val, scoring='accuracy', \n                               return_train_score=True)\n\ngrid_search_rf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search_rf.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cvres = grid_search_rf.cv_results_\nfor mean_score, params in zip(cvres['mean_test_score'], cvres['params']) :\n    print(round(mean_score, 4), params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = results.append({'Model Type' : 'Random Forest',\n                          'Model Name' : 'grid_search_rf',\n                          'Accuracy' : grid_search_rf.best_score_ ,\n                          'Hyperparameters' : grid_search_rf.best_params_}, ignore_index=True)\n\n# View results so far\nresults","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# With bagging\nbag_grd = BaggingClassifier(DecisionTreeClassifier(), random_state = rnd_st, bootstrap=True)\n\nparam_grid_bag = [\n    {\n        'n_estimators' : [10, 100, 500],\n        'max_samples' : [10, 100, 500],\n    }\n]\n\ngrid_search_bag = GridSearchCV(bag_grd, param_grid_bag, cv = cross_val, scoring='accuracy', \n                               return_train_score=True)\n\ngrid_search_bag.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search_bag.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = results.append({'Model Type' : 'Random Forest with Bagging',\n                          'Model Name' : 'grid_search_bag',\n                          'Accuracy' : grid_search_bag.best_score_ ,\n                          'Hyperparameters' : grid_search_bag.best_params_}, ignore_index=True)\n\n# View results so far\nresults","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neural Network","metadata":{}},{"cell_type":"code","source":"# Multi-layer perception algorithm using backpropogation\nmlp_grd = MLPClassifier(random_state = rnd_st, alpha=1e-5, max_iter = 10000)\n\nparam_grid_mlp = [\n    {\n        'hidden_layer_sizes' : [1, 2, 4],\n        'solver' : ['lbfgs','sgd','adam'],\n        'learning_rate' : ['constant','invscaling','adaptive']\n    },\n]\n\ngrid_search_mlp = GridSearchCV(mlp_grd, param_grid_mlp, cv = cross_val, scoring='accuracy', \n                               return_train_score=True)\n\ngrid_search_mlp.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search_mlp.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cvres = grid_search_mlp.cv_results_\nfor mean_score, params in zip(cvres['mean_test_score'], cvres['params']) :\n    print(round(mean_score, 4), params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = results.append({'Model Type' : 'Multi-layer Perception NN',\n                          'Model Name' : 'grid_search_mlp',\n                          'Accuracy' : grid_search_mlp.best_score_ ,\n                          'Hyperparameters' : grid_search_mlp.best_params_}, ignore_index=True)\n\n# View results so far\nresults","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gaussian Naive Bayes","metadata":{}},{"cell_type":"code","source":"gnb_grd = GaussianNB()\n\nparam_grid_gnb = [\n    {\n        'var_smoothing' : [.0001, 1e-9]\n    },\n]\n\ngrid_search_gnb = GridSearchCV(gnb_grd, param_grid_gnb, cv = cross_val, scoring='accuracy', \n                               return_train_score=True)\n\ngrid_search_gnb.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search_gnb.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cvres = grid_search_gnb.cv_results_\nfor mean_score, params in zip(cvres['mean_test_score'], cvres['params']) :\n    print(round(mean_score, 4), params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = results.append({'Model Type' : 'Gaussian Naive Bayes',\n                          'Model Name' : 'grid_search_gnb',\n                          'Accuracy' : grid_search_gnb.best_score_ ,\n                          'Hyperparameters' : grid_search_gnb.best_params_}, ignore_index=True)\n\n# View results so far\nresults","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble Model","metadata":{}},{"cell_type":"code","source":"# Create a list of models\nestimators = []\nestimators.append(('Logistic Regression',grid_search_log))\nestimators.append(('Decision Tree',grid_search_tree))\nestimators.append(('Support Vector Machine',grid_search_svm))\nestimators.append(('Random Forest',grid_search_rf))\nestimators.append(('Random Forest w Bagging',grid_search_rf))\nestimators.append(('MLP NN',grid_search_mlp))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit to the voting classifier\nfrom sklearn.ensemble import VotingClassifier\nensemble = VotingClassifier(estimators)\nensemble.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Export the predictions","metadata":{}},{"cell_type":"code","source":"y_predict = ensemble.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = pd.DataFrame()\npred['PassengerId'] = titanic_tst['PassengerId']\npred['Survived'] = y_predict\npred.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}